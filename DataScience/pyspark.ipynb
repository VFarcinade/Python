{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4f2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f890cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a210d06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-OO3T2N8I:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x195575bce20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9544080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('train.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bd5124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('AP', 'string'),\n",
       " ('creation_date_answer', 'timestamp'),\n",
       " ('situation', 'int'),\n",
       " ('ctc', 'string'),\n",
       " ('location', 'int'),\n",
       " ('gc_id', 'int'),\n",
       " ('gc_label', 'string'),\n",
       " ('creation_date_global', 'timestamp'),\n",
       " ('id_group', 'string'),\n",
       " ('id_group_2', 'string'),\n",
       " ('favorite_fruit', 'string'),\n",
       " ('fruit_situation_id', 'int'),\n",
       " ('fruit_situation_label', 'string'),\n",
       " ('fruits_or_vegetables', 'string'),\n",
       " ('number_of_fruit', 'int'),\n",
       " ('id_group_3', 'string'),\n",
       " ('creation_date_request', 'timestamp'),\n",
       " ('hobby', 'string'),\n",
       " ('id_group_4', 'string'),\n",
       " ('ville', 'string'),\n",
       " ('green_vegetables', 'string'),\n",
       " ('vegetable_type', 'string'),\n",
       " ('target', 'int')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,p = (df.count(), len(df.columns))\n",
    "print(n,p)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a129da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppression des colonnes NA\n",
      "ctc:  15380\n",
      "fruit_situation_label:  1728\n",
      "fruits_or_vegetables:  17341\n",
      "ville:  16912\n",
      "vegetable_type:  24586\n"
     ]
    }
   ],
   "source": [
    "# Find count for empty, None, Null, Nan with string literals.\n",
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "print(\"Suppression des colonnes NA\")\n",
    "\n",
    "to_delete=[]\n",
    "\n",
    "nan_count = df.select(*[(\n",
    "        F.count(F.when((F.isnan(c) | F.col(c).isNull()), c)) if t not in (\"timestamp\", \"date\")\n",
    "        else F.count(F.when(F.col(c).isNull(), c))\n",
    "    ).alias(c)\n",
    "    for c, t in df.dtypes if c in df.columns\n",
    "])\n",
    "\n",
    "for l in df.columns:\n",
    "    count_NA = nan_count.collect()[0][l] \n",
    "    if ( count_NA > 0 ):\n",
    "        print(l+ \":  \" + str(count_NA))\n",
    "        to_delete.append(l)\n",
    "        df = df.drop(l)\n",
    "\n",
    "#df.drop(label(to_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce930432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppression des colonnes non exploitables\n"
     ]
    }
   ],
   "source": [
    "print(\"Suppression des colonnes non exploitables\")\n",
    "\n",
    "df = df.drop(\"id\",\"id_group\",\"id_group_2\",\"id_group_3\",\"id_group_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da3c507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes contenant même info: gc_id & gc_label\n",
      "On en supprime une des deux: gc_label\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes contenant même info: gc_id & gc_label\")\n",
    "#df.groupBy(\"gc_id\").count().sort('count').show()\n",
    "#df.groupBy(\"gc_label\").count().sort('count').show()\n",
    "print(\"On en supprime une des deux: gc_label\")\n",
    "df=df.drop('gc_label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "987a09fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, hour\n",
    "\n",
    "df = df.select(*df.columns,year(df.creation_date_answer).alias('year_creation_date_answer'), \n",
    "                month(df.creation_date_answer).alias('month_creation_date_answer'),\n",
    "                dayofmonth(df.creation_date_answer).alias('day_creation_date_answer'), \n",
    "                hour(df.creation_date_answer).alias('hour_creation_date_answer'),\n",
    "                year(df.creation_date_global).alias('year_creation_date_global'), \n",
    "                month(df.creation_date_global).alias('month_creation_date_global'),\n",
    "                dayofmonth(df.creation_date_global).alias('day_creation_date_global'), \n",
    "                hour(df.creation_date_global).alias('hour_creation_date_global'),\n",
    "                year(df.creation_date_request).alias('year_creation_date_request'), \n",
    "                month(df.creation_date_request).alias('month_creation_date_request'),\n",
    "                dayofmonth(df.creation_date_request).alias('day_creation_date_request'), \n",
    "                hour(df.creation_date_request).alias('hour_creation_date_request'),\n",
    "               )\n",
    "\n",
    "df=df.drop(\"creation_date_answer\",\"creation_date_global\",\"creation_date_request\");\n",
    "\n",
    "#df.select(\"year_creation_date_answer\",\"month_creation_date_answer\",\"day_creation_date_answer\",\"hour_creation_date_answer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5214c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP: 2\n",
      "situation: 8\n",
      "location: 99\n",
      "gc_id: 12\n",
      "favorite_fruit: 2\n",
      "fruit_situation_id: 22\n",
      "number_of_fruit: 9\n",
      "hobby: 3\n",
      "green_vegetables: 2\n",
      "target: 4\n",
      "year_creation_date_answer: 1\n",
      "month_creation_date_answer: 3\n",
      "day_creation_date_answer: 31\n",
      "hour_creation_date_answer: 24\n",
      "year_creation_date_global: 9\n",
      "month_creation_date_global: 12\n",
      "day_creation_date_global: 31\n",
      "hour_creation_date_global: 24\n",
      "year_creation_date_request: 1\n",
      "month_creation_date_request: 3\n",
      "day_creation_date_request: 31\n",
      "hour_creation_date_request: 24\n"
     ]
    }
   ],
   "source": [
    "for label in df.columns:\n",
    "    count_occ = df.select(label).distinct().count()\n",
    "    print(label+\": \"+str(count_occ))\n",
    "    if(count_occ == 1) : df=df.drop(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f57e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AP', 'string'),\n",
       " ('situation', 'int'),\n",
       " ('location', 'int'),\n",
       " ('gc_id', 'int'),\n",
       " ('favorite_fruit', 'string'),\n",
       " ('fruit_situation_id', 'int'),\n",
       " ('number_of_fruit', 'int'),\n",
       " ('hobby', 'string'),\n",
       " ('green_vegetables', 'string'),\n",
       " ('target', 'int'),\n",
       " ('month_creation_date_answer', 'int'),\n",
       " ('day_creation_date_answer', 'int'),\n",
       " ('hour_creation_date_answer', 'int'),\n",
       " ('year_creation_date_global', 'int'),\n",
       " ('month_creation_date_global', 'int'),\n",
       " ('day_creation_date_global', 'int'),\n",
       " ('hour_creation_date_global', 'int'),\n",
       " ('month_creation_date_request', 'int'),\n",
       " ('day_creation_date_request', 'int'),\n",
       " ('hour_creation_date_request', 'int')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,p = (df.count(), len(df.columns))\n",
    "print(n,p)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac8429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 't']\n",
      "['clementine', 'poire']\n",
      "['noball', 'football', 'volleyball']\n",
      "['f', 't']\n"
     ]
    }
   ],
   "source": [
    "#ONE HOT ENCODING:\n",
    "\n",
    "str_lab=[]\n",
    "\n",
    "for lab in df.dtypes:\n",
    "    if(lab[1]==\"string\"): str_lab.append(lab[0])\n",
    "        \n",
    "for l in str_lab:\n",
    "    col = df.select(l).distinct().collect()\n",
    "    col = [item for sublist in col for item in sublist]\n",
    "    print(col)\n",
    "    for i in range(len(col)-1):\n",
    "        df=df.withColumn(l+\"_\"+str(i), (df[l]==col[i]).cast(\"int\"))\n",
    "    df=df.drop(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bc8da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyspark.ml.feature import StringIndexer\\n\\nstr_lab = []\\nstr_lab_idx = []\\nfor lab in df.dtypes:\\n    if(lab[1]==\"string\"): \\n        str_lab.append(lab[0])\\n        str_lab_idx.append(lab[0]+\"_idx\")                \\n\\nprint(str_lab)\\n        \\nindexer = StringIndexer(inputCols = str_lab, outputCols = str_lab_idx)\\n\\ndf = indexer.fit(df).transform(df)\\n\\nfor s in str_lab: df = df.drop(s)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ORDINAL ENCODING\n",
    "\n",
    "'''\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "str_lab = []\n",
    "str_lab_idx = []\n",
    "for lab in df.dtypes:\n",
    "    if(lab[1]==\"string\"): \n",
    "        str_lab.append(lab[0])\n",
    "        str_lab_idx.append(lab[0]+\"_idx\")                \n",
    "\n",
    "print(str_lab)\n",
    "        \n",
    "indexer = StringIndexer(inputCols = str_lab, outputCols = str_lab_idx)\n",
    "\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "for s in str_lab: df = df.drop(s)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b2e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 21\n",
      "root\n",
      " |-- situation: integer (nullable = true)\n",
      " |-- location: integer (nullable = true)\n",
      " |-- gc_id: integer (nullable = true)\n",
      " |-- fruit_situation_id: integer (nullable = true)\n",
      " |-- number_of_fruit: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- month_creation_date_answer: integer (nullable = true)\n",
      " |-- day_creation_date_answer: integer (nullable = true)\n",
      " |-- hour_creation_date_answer: integer (nullable = true)\n",
      " |-- year_creation_date_global: integer (nullable = true)\n",
      " |-- month_creation_date_global: integer (nullable = true)\n",
      " |-- day_creation_date_global: integer (nullable = true)\n",
      " |-- hour_creation_date_global: integer (nullable = true)\n",
      " |-- month_creation_date_request: integer (nullable = true)\n",
      " |-- day_creation_date_request: integer (nullable = true)\n",
      " |-- hour_creation_date_request: integer (nullable = true)\n",
      " |-- AP_0: integer (nullable = true)\n",
      " |-- favorite_fruit_0: integer (nullable = true)\n",
      " |-- hobby_0: integer (nullable = true)\n",
      " |-- hobby_1: integer (nullable = true)\n",
      " |-- green_vegetables_0: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n,p = (df.count(), len(df.columns))\n",
    "print(n,p)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12d7dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_csv(\"train_clean_pyspark.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "197913a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                   X|  y|\n",
      "+--------------------+---+\n",
      "|[-1.0,52.0,70.0,1...|  0|\n",
      "|[-1.0,78.0,10.0,1...|  1|\n",
      "|[-1.0,70.0,10.0,2...|  0|\n",
      "|[-1.0,84.0,10.0,1...|  1|\n",
      "|[-1.0,29.0,20.0,1...|  1|\n",
      "|[-1.0,32.0,10.0,2...|  0|\n",
      "|[-1.0,96.0,30.0,2...|  0|\n",
      "|[-1.0,43.0,10.0,1...|  0|\n",
      "|[-1.0,50.0,10.0,1...|  1|\n",
      "|[-1.0,47.0,10.0,1...|  0|\n",
      "|[-1.0,3.0,10.0,10...|  1|\n",
      "|[-1.0,60.0,10.0,2...|  0|\n",
      "|[-1.0,70.0,40.0,2...|  0|\n",
      "|[-1.0,68.0,10.0,2...|  0|\n",
      "|[-1.0,95.0,100.0,...|  3|\n",
      "|[-1.0,95.0,20.0,1...|  0|\n",
      "|[-1.0,8.0,70.0,10...|  1|\n",
      "|[-1.0,70.0,10.0,2...|  1|\n",
      "|[-1.0,78.0,20.0,2...|  1|\n",
      "|[-1.0,34.0,30.0,2...|  0|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureAssembler = VectorAssembler(inputCols=df.select([c for c in df.columns if c not in {'target'}]).columns, outputCol = \"X\")\n",
    "data = featureAssembler.transform(df)\n",
    "data = data.select(\"X\",\"target\")\n",
    "data = data.withColumnRenamed(\"target\", \"y\")\n",
    "data.columns\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5508754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "|  0|12077|\n",
      "|  1| 8816|\n",
      "|  2| 3874|\n",
      "|  3|  233|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"y\").count().sort('y').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eb86d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.75,0.25])\n",
    "clf_reg = LinearRegression(featuresCol=\"X\", labelCol=\"y\").fit(train_data)\n",
    "#..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
