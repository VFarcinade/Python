{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6lGZz2LvFrC"
   },
   "source": [
    "# Automatic differentiation lab work\n",
    "\n",
    "*Notebook prepared by Mathieu Blondel, November 2020.\n",
    "The accompanying slides are available [here](https://www.mblondel.org/teaching/autodiff-2020.pdf).*\n",
    "\n",
    "In this lab work, we are going to implement reverse differentiation (a.k.a. backpropagation) for a feedforward network (that is, the composition of a **sequence** or **chain** of functions).\n",
    "\n",
    "## Numerical differentiation utilities\n",
    "\n",
    "In this section, I define utility functions for computing Jacobians, Jacobian-vector products (VJPs), and vector Jacobian products (VJPs). You will need to use them to check the correctness of your implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4n6JlkxIb_V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def num_jvp(f, x, v, eps=1e-6):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    f: a function returning an array.\n",
    "    x: an array.\n",
    "    v: an array (same shape as x).\n",
    "\n",
    "  Returns:\n",
    "    numerical_jvp\n",
    "  \"\"\"\n",
    "  if not np.array_equal(x.shape, v.shape):\n",
    "    raise ValueError(\"x and v should have the same shape.\")\n",
    "\n",
    "  return (f(x + eps * v) - f(x - eps * v)) / (2 * eps)\n",
    "\n",
    "def num_jacobian(f, x, eps=1e-6):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    f: a function returning an array.\n",
    "    x: an array (only 1d and 2d arrays supported).\n",
    "\n",
    "  Returns:\n",
    "    numerical_jacobian\n",
    "  \"\"\"\n",
    "  def e(i):\n",
    "    ret = np.zeros_like(x)\n",
    "    ret[i] = 1\n",
    "    return ret\n",
    "\n",
    "  def E(i, j):\n",
    "    ret = np.zeros_like(x)\n",
    "    ret[i, j] = 1\n",
    "    return ret\n",
    "\n",
    "  if len(x.shape) == 1:\n",
    "    return np.array([num_jvp(f, x, e(i), eps=eps) for i in range(len(x))]).T\n",
    "  elif len(x.shape) == 2:\n",
    "    return np.array([[num_jvp(f, x, E(i, j), eps=eps) \\\n",
    "                     for i in range(x.shape[0])] \\\n",
    "                     for j in range(x.shape[1])]).T\n",
    "  else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "def num_vjp(f, x, u, eps=1e-6):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    f: a function returning an array.\n",
    "    x: an array (only 1d and 2d arrays supported).\n",
    "\n",
    "  Returns:\n",
    "    numerical_vjp\n",
    "  \"\"\"\n",
    "  J = num_jacobian(f, x, eps=eps)\n",
    "  if len(J.shape) == 2:\n",
    "    return J.T.dot(u)\n",
    "  elif len(J.shape) == 3:\n",
    "    shape = J.shape[1:]\n",
    "    J = J.reshape(J.shape[0], -1)\n",
    "    return u.dot(J).reshape(shape)\n",
    "  else:\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn8-CxAHIqVD"
   },
   "source": [
    "## Vector Jacobian products (VJPs) for basic primitives\n",
    "\n",
    "In this section, we are going to define VJPs for basic primitives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBW-vGb8Ksra"
   },
   "outputs": [],
   "source": [
    "def dot(x, W):\n",
    "  return np.dot(W, x)\n",
    "\n",
    "def dot_make_vjp(x, W):\n",
    "  def vjp(u):\n",
    "    return W.T.dot(u), np.outer(u, x)\n",
    "  return vjp\n",
    "\n",
    "dot.make_vjp = dot_make_vjp\n",
    "\n",
    "def squared_loss(y_pred, y):\n",
    "  # The code requires every output to be an array.\n",
    "  return np.array([0.5 * np.sum((y - y_pred) ** 2)])\n",
    "\n",
    "def squared_loss_make_vjp(y_pred, y):\n",
    "  diff = y_pred - y\n",
    "\n",
    "  def vjp(u):\n",
    "    return diff * u, -diff * u\n",
    "\n",
    "  return vjp\n",
    "\n",
    "squared_loss.make_vjp = squared_loss_make_vjp\n",
    "\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "def add_make_vjp(a, b):\n",
    "  gprime = np.ones(len(a))\n",
    "\n",
    "  def vjp(u):\n",
    "    return u * gprime, u * gprime\n",
    "\n",
    "  return vjp\n",
    "\n",
    "add.make_vjp = add_make_vjp\n",
    "\n",
    "def mul(a, b):\n",
    "  return a * b\n",
    "\n",
    "def mul_make_vjp(a, b):\n",
    "  gprime_a = b\n",
    "  gprime_b = a\n",
    "\n",
    "  def vjp(u):\n",
    "    return u * gprime_a, u * gprime_b\n",
    "\n",
    "  return vjp\n",
    "\n",
    "mul.make_vjp = mul_make_vjp\n",
    "\n",
    "def exp(x):\n",
    "  return np.exp(x)\n",
    "\n",
    "def exp_make_vjp(x):\n",
    "  gprime = exp(x)\n",
    "\n",
    "  def vjp(u):\n",
    "    return u * gprime,\n",
    "\n",
    "  return vjp\n",
    "\n",
    "exp.make_vjp = exp_make_vjp\n",
    "\n",
    "def sqrt(x):\n",
    "  return np.sqrt(x)\n",
    "\n",
    "def sqrt_make_vjp(x):\n",
    "  gprime = 1. / (2 * sqrt(x))\n",
    "\n",
    "  def vjp(u):\n",
    "    return u * gprime,\n",
    "\n",
    "  return vjp\n",
    "\n",
    "sqrt.make_vjp = sqrt_make_vjp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyZTVrEQNdJR"
   },
   "source": [
    "**Exercise 1** \n",
    "\n",
    "Look at the \"exp\" and \"sqrt\"  examples above and define the primitive and its associated VJP for the relu function `relu(x) = np.maximum(x, 0)`. Check the correctness of your implementation using the `num_vjp` utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luk7y1NqNue2"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "  return \n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "x = rng.randn(5)\n",
    "u = rng.randn(5)\n",
    "\n",
    "# Check the correctness of your vjp using num_vjp:\n",
    "# num_vjp(relu.vjp, x, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH37U1gpN86J"
   },
   "source": [
    "## Reverse differentiation of feedforward networks\n",
    "\n",
    "Feedforward networks use a sequence of functions. The functions can either be of the form `func(x, param)` if the function has learnable parameters (e.g., `dot(x, W)`) or `func(x)` if the function doesn't have learnable parameters (e.g., `exp(x)`). \n",
    "\n",
    "We represent a feedforward network using a list of functions and a list of parameters. Let us create a small utility function for creating such a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jf-ZYYjlQb9R"
   },
   "outputs": [],
   "source": [
    "def create_feed_forward(n, y, seed=0):\n",
    "  rng = np.random.RandomState(seed)\n",
    "\n",
    "  funcs = [\n",
    "    dot,\n",
    "    relu,\n",
    "    dot,\n",
    "    relu,\n",
    "    dot,\n",
    "    squared_loss\n",
    "  ]\n",
    "\n",
    "  params = [\n",
    "    rng.randn(3, n),\n",
    "    None,\n",
    "    rng.randn(4, 3),\n",
    "    None,\n",
    "    rng.randn(1, 4),\n",
    "    y\n",
    "  ]\n",
    "\n",
    "  return funcs, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TEs4xEGQySA"
   },
   "source": [
    "Next, let us create a small utility function for correctly calling each function, depending on whether it has 1 or 2 arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8-rUfSlQ6-s"
   },
   "outputs": [],
   "source": [
    "def call_func(x, func, param):\n",
    "  \"\"\"Make sure the function is called with the correct number of arguments.\"\"\"\n",
    "\n",
    "  if param is None:\n",
    "    # Unary function\n",
    "    return func(x)\n",
    "  else:\n",
    "    # Binary function\n",
    "    return func(x, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcR14zoMRPUC"
   },
   "source": [
    "**Exercise 2.** \n",
    "\n",
    "Implement the following function for evaluating the feedforward network. Check that the returned value is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmnpMz9bRx-Q"
   },
   "outputs": [],
   "source": [
    "def evaluate_chain(x, funcs, params, return_all=False):\n",
    "  \"\"\"\n",
    "  Evaluate a chain of functions.\n",
    "\n",
    "  Args:\n",
    "    x: initial input to the chain.\n",
    "    funcs: a list of functions of the form func(x) or func(x, param).\n",
    "    params: a list of parameters, with len(params) = len(funcs).\n",
    "            If a function doesn't have parameters, use None.\n",
    "    return_all: whether to return all intermediate values or only the last one.\n",
    "\n",
    "  Returns:\n",
    "    value (return_all == False) or values (return_all=True)\n",
    "  \"\"\"\n",
    "  if len(funcs) != len(params):\n",
    "    raise ValueError(\"len(funcs) and len(params) should be equal.\")\n",
    "\n",
    "  if return_all:\n",
    "    return\n",
    "  else:\n",
    "    return\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "x = rng.randn(2)\n",
    "y = 1.5\n",
    "\n",
    "funcs, params = create_feed_forward(n=len(x), y=y, seed=0)\n",
    "W1, _, W3, _, W5, y = params\n",
    "\n",
    "# Make sure that `evaluate_chain(x, funcs, params)` returns the same value as\n",
    "# a manual implementaton:\n",
    "# x1 = dot(x, W1)\n",
    "# x2 = relu(x1)\n",
    "# x3 = dot(x2, W3)\n",
    "# x4 = relu(x3)\n",
    "# x5 = dot(x4, W5)\n",
    "# value = squared_loss(x5, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuZNM-6yT0gp"
   },
   "source": [
    "**Exercise 3.**\n",
    "\n",
    "Reusing the previous function with `return_all=True`, implement the following function that returns both the network value and the Jacobian w.r.t. `x`. Check correctness of the Jacobian using `num_jacobian`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmXeQ34TULOP"
   },
   "outputs": [],
   "source": [
    "def call_vjp(x, func, param, u):\n",
    "  \"\"\"Make sure the vjp is called with the correct number of arguments.\"\"\"\n",
    "  if param is None:\n",
    "    vjp = func.make_vjp(x)\n",
    "    vjp_x, = vjp(u)\n",
    "    vjp_param = None\n",
    "  else:\n",
    "    vjp = func.make_vjp(x, param)\n",
    "    vjp_x, vjp_param = vjp(u)\n",
    "  return vjp_x, vjp_param\n",
    "\n",
    "\n",
    "def reverse_diff_chain(x, funcs, params):\n",
    "  \"\"\"\n",
    "  Reverse-mode differentiation of a chain of computations.\n",
    "\n",
    "  Args:\n",
    "    x: initial input to the chain.\n",
    "    funcs: a list of functions of the form func(x) or func(x, param).\n",
    "    params: a list of parameters, with len(params) = len(funcs).\n",
    "            If a function doesn't have parameters, use None.\n",
    "\n",
    "  Returns:\n",
    "    value, Jacobian w.r.t. x\n",
    "  \"\"\"\n",
    "  # Evaluate the feedforward model and store intermediate computations,\n",
    "  # as they will be needed during the backward pass.\n",
    "  xs = evaluate_chain(x, funcs, params, return_all=True)\n",
    "\n",
    "  m = xs[-1].shape[0]  # Output size\n",
    "  K = len(funcs)  # Number of functions.\n",
    "\n",
    "  # We need a list as the shape of U can change.\n",
    "  U = list(np.eye(m))\n",
    "\n",
    "  for k in reversed(range(K)):\n",
    "    # Implement backward differentiation here\n",
    "\n",
    "  return xs[-1], np.array(U)\n",
    "\n",
    "# Check correctness of Jacobian using `num_jacobian`.\n",
    "# def f(x):\n",
    "#   return evaluate_chain(x, funcs, params)\n",
    "# # num_jacobian only accepts functions of one argument.\n",
    "# num_jac = num_jacobian(f, x)\n",
    "# value, jac = reverse_diff_chain(x, funcs, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fvXX-HaVz4Y"
   },
   "source": [
    "**Bonus exercise.**\n",
    "\n",
    "Modify the above function to also return the Jacobians w.r.t. W1, W3, W5. Check correctness using `num_jacobian`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Autodiff lab work",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
